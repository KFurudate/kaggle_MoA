{"cells":[{"metadata":{},"cell_type":"markdown","source":"\nThanks for:\n* https://www.kaggle.com/sishihara/moa-lgbm-benchmark#Preprocessing\n\n* https://www.kaggle.com/ttahara/osic-baseline-lgbm-with-custom-metric\n\n* https://zenn.dev/fkubota/articles/2b8d46b11c178ac2fa2d\n\n* https://qiita.com/ryouta0506/items/619d9ac0d80f8c0aed92\n\n* https://github.com/nejumi/tools_for_kaggle/blob/master/semi_supervised_learner.py\n\n* https://upura.hatenablog.com/entry/2019/03/03/233534\n\n* https://pompom168.hatenablog.com/entry/2019/07/22/113433\n\n* https://www.kaggle.com/c/lish-moa/discussion/193878\n\n* https://tsumit.hatenablog.com/entry/2020/06/20/044835\n\n* https://www.kaggle.com/kushal1506/moa-pytorch-feature-engineering-0-01846\n\n* https://www.kaggle.com/c/lish-moa/discussion/195195\n\n* https://www.kaggle.com/gogo827jz/self-stacking-groupcv-xgboost\n\n* https://www.kaggle.com/c/lish-moa/discussion/197158\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Version = \"v1\" # starter model\n# Version = \"v2\" # Compare treat Vs. ctrl and minor modifications, StratifiedKFold\n# Version = \"v3\" # Add debug mode and minor modifications\n# Version = \"v4\" # Clipping a control with an outlier(25-75)\n# Version = \"v5\" # Clipping a control with an outlier(20-80)\n# Version = \"v6\" # under sampling 500 → oversamplling 500, lipping a control with an outlier(10-90)\n# Version = \"v7\" # Use anotated data, under sampling 500 → oversamplling 500, clipping a control with an outlier(10-90)\n# Version = \"v8\" # pseudo labeling (thresholds:0.5), timeout\n# Version = \"v9\" # pseudo labeling (thresholds:0.6), timeout\n# Version = \"v10\" # pseudo labeling (thresholds:0.6), ReduceCol: Kolmogorov-Smirnov, PCA(whiten)&UMAP\n# Version = \"v11\" # pseudo labeling (thresholds:0.6), ReduceCol: Kolmogorov-Smirnov, PCA(whiten)&UMAP, lgbm parames adjust\n# Version = \"v12\" # Feature engineering based on feature importance\n# Version = \"v13\" # Calibration, SMOTE(k_neighbors=5→1)\n# Version = \"v14\" # Removed the Calibration, SMOTE(k_neighbors=1), pseudo labeling (thresholds:0.7)\n# Version = \"v15\" # Updata anotated data\n# Version = \"v16\" # Remove noisy label(confidence: 0.5)\n# Version = \"v17\" # Modifications with remove noisy label func, Calibration, confidence = y_prob.probability.max()*0.3\n# Version = \"v18\" # SMOTE(k_neighbors=1→2), confidence = y_prob.probability.max()*0.2\n# Version = \"v19\" # SMOTE(k_neighbors=2→3),\n# Version = \"v20\" # Modifications with confidence, Removed the Calibration, SMOTE(k_neighbors=2), \n# Version = \"v21\" # DEBUG = False\n# Version = \"v22\" # minor modifications\n# Version = \"v23\" # TOP100→PCA→UMAP(n_components=3)\n# Version = \"v24\" # TOP100→PCA→UMAP(n_components=10), UMAP(n_components=2→3)\n# Version = \"v25\" # Feature engineering based on Feature importance\n# Version = \"v26\" # Modify pseudo labeling func to exclude low confidence pseudo labels in the TEST data.\n# Version = \"v27\" # LGBMClassifie:clf.predict→clf.predict_proba\n# Version = \"v28\" # Calibration (No calbration:CV:0.06542)\n# Version = \"v29\" # Remove Calibration, is_unbalance': True, SMOTE(k_neighbors=2→3), Modify pseudo labeling func to include low confidence pseudo labels in the TEST data, target_rate *= 1.2\n# Version = \"v30\" # drop_duplicates(keep=\"last\")\n# Version = \"v31\" # target_rate *= 1.1, if Threshold <= 0.2: break, if sum(p_label)*1.5 >= check: break, if sum(p_label) <= check*1.5: break\n# Version = \"v32\" # y_prob.probability.quantile(0.3), if Threshold >= 0.95: break\n# Version = \"v33\" # RankGauss, Scaled by category, SMOTE(k_neighbors=2),\n# Version = \"v34\" # RankGauss apply c-columns, remove TOP100, Add f_diff = lambda x: x - med, Create features\n# Version = \"v35\" # f_div = lambda x: ((x+d)*10 / (abs(med)+d))**2, f_diff = lambda x: ((x-med)*10)**2, select features\n# Version = \"v36\" # Add feature importance func\n# Version = \"v37\" # Remove RankGauss for gene expression, fix feature importance func\n# Version = \"v38\" # Add MultiLabel Stratification func, fix index of data before split with \"data = data.sort_index(axis='index')\"\"\n# Version = \"v39\" # fix pseudo labeling func\n# Version = \"v40\" # fix pseudo labeling func, create importance_cols_df with all columns\n# Version = \"v41\" # Feature engineering based on Feature importance with v39 notebook\n# Version = \"v42\" # Feature engineering based on Feature importance with v40 notebook\n# Version = \"v40.2\" # Select, update fe_stats func based on v40 note book\n# Version = \"v42.1\" # Remove Kolmogorov-Smirnov test and VarianceThreshold for inference, Threshold = np.quantile(y_prob, q=0.99)\n# Version = \"v43\" # Inference, modify pseudo labeling func: lower, upper, change param 3→2.1\n# Version = \"v44.1\" # Select,\n# Version = \"v44.2\" # inference used v40.2 note book(updated fe_stats func), DEBUG=False, modify  eature_Engineering func, check*(3.5-len(str(int(check))))\n# Version = \"v45\" # inference used v40.2, DEBUG=False, Add create_features func,  learning_rate(pseudo labeling): 0.01→0.02\n# Version = \"v46\" # Select, Add 'g_d_g', 'c_d_c', 'g_df_g', 'c_df_c', 'd_g_df_g', 'd_c_df_c' to the kind_list, VarianceThreshold(0.91) \n# Version = \"v47\" # Select, Add detect_neg func but time over 9 hours\n# Version = \"v48\" # inference used v46, DEBUG=False, modify Feature_Engineering func\n# Version = \"v49\" # inference used v46, DEBUG=False, create_features(func=\"mean\")\n# Version = \"v50\" # Select, QuantileTransformer(n_quantiles=100), select_importance_cols(num=50)\n# Version = \"v51\" # Select, QuantileTransformer(n_quantiles=defalt), select_importance_cols(num=100)\n# Version = \"v52\" # inference used v46, adjust params in pseudo_labeling func\n# Version = \"v53\" # Select, feature engining→VarianceThreshold(0.98), select_importance_cols(num=200)\n# Version = \"v54\" # inference used v50, Not using create_cluster func \n# Version = \"v55\" # inference used v51, Not using create_cluster func\n# Version = \"v56\" # inference used v51, adjust lgbm params: 'subsample': 0.7,'subsample_freq': 3, 'lambda_l2':0.2,\n# Version = \"v57\" # inference used v51, adjust lgbm params: 'subsample': 0.7,'subsample_freq': 3, 'lambda_l2':3,\n# Version = \"v58\" # inference used v53, adjust lgbm params; 'lambda_l2':3,\n# Version = \"v59\" # inference used v53, adjust lgbm params; 'lambda_l2':15,\n# Version = \"v60\" # inference used v53, adjust lgbm params; 'lambda_l2':0.1,'bagging_fraction': 0.7, 'bagging_freq': 1, 'learning_rate': 0.03,\n# Version = \"v61\" # inference used v53, adjust lgbm params; 'lambda_l2':3,'bagging_fraction': 0.7, 'bagging_freq': 1, 'learning_rate': 0.03,\n# Version = \"v62\" # inference used v53, self-Stacking prediction values, Threshold += 0.05, 'learning_rate': 0.05, 'lambda_l2':3\n# Version = \"v63\" # inference used v53, adjust lgbm params; 'lambda_l2':15,\n# Version = \"v64\" # inference used v53, if iter_ == max_iter: X_test[\"pred_feat\"] = y_prob.copy()\n# Version = \"v65\" # inference used v53, Apply RankGauss(df) to \"pred_feat\"\n# Version = \"v66\" # inference used v53, Apply clipping & RankGauss(df) to \"pred_feat\"\n# Version = \"v67\" # Select, VarianceThreshold(0.98), select_importance_cols(num=300)\n# Version = \"v68\" # inference used v67, np.clip\n# Version = \"v69\" # inference used v67, if _score > 0.02: np.clip\n# Version = \"v70\" # inference used v67, adjust prediction\n# Version = \"v71\" # inference used v67, (Threshold+0.03) >= 0.96\n# Version = \"v72\" # inference used v67, remove \"if (p_label_rate*1.5) < target_rate\" from the Adj_threshold func\n# Version = \"v73\" # inference used v67, exclusive_cols→Under_Sampling func\n# Version = \"v74\" # inference used v67, feature engining for unpredictable_cols(create_features func 30)\n# Version = \"v75\" # inference used v67, avoid overfit for unpredictable_cols\n# Version = \"v76\" # inference used v67, adjust lgm params; 'feature_fraction':0.1, 'lambda_l2': 200,\n# Version = \"v77\" # inference used v67, Add pca to create_features func \n# Version = \"v78\" # inference used v67, adjust lgbm params; 'lambda_l2': 300, 'bagging_fraction': 0.7,'colsample_bytree': 0.05,'subsample': 0.7,'reg_lambda': 100,\n# Version = \"v79\" # inference used v67, adjust lgbm params; 'lambda_l2': 300, 'bagging_fraction': 0.7,'colsample_bytree': 0.04,　'subsample': 0.7,'reg_lambda': 200,\n# Version = \"v80\" # inference used v67, lgm params used v78, N_FOLD = 5\n# Version = \"v81\" # inference used v67, lgm params used v78, N_FOLD = 5&Early_stopping_rounds=29, unpredictable_cols→ N_FOLD = 3 & Early_stopping_rounds=39\n# Version = \"v82\" # Select, DEBUG = True, 'feature_fraction':0.007, select_importance_cols(num=300),\n# Version = \"v83\" # inference used v67, lgm params used　v79, odds_gene_df[\"Log\"] < 1.0→0.0\n\nVersion = \"v84\" # Select, based on v83, DEBUG = False, 'feature_fraction':0.007, select_importance_cols(num=300),","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#DEBUG = True\nDEBUG = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Library"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\nfrom logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nimport random\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss, roc_auc_score, average_precision_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.notebook import tqdm\nimport torch\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"lightgbm Version: \", lgb.__version__)\nprint(\"imblearn Version: \", imblearn.__version__)\nprint(\"numpy Version: \", np.__version__)\nprint(\"pandas Version: \", pd.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utils"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_logger(filename='log'):\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.{Version}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nlogger = get_logger()\n\ndef seed_everything(seed=777):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Config"},{"metadata":{"trusted":true},"cell_type":"code","source":"if DEBUG:\n    N_FOLD = 2\n    Num_boost_round=1000\n    Early_stopping_rounds=10\nelse:\n    N_FOLD = 4\n    Num_boost_round=10000\n    Early_stopping_rounds=30\n\nSEED = 42\nseed_everything(seed=SEED)\n\nMax_depth = 7","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Loading"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/lish-moa/train_features.csv\")\ntest = pd.read_csv(\"../input/lish-moa/test_features.csv\")\ntrain_targets_scored = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\ntrain_targets_nonscored = pd.read_csv(\"../input/lish-moa/train_targets_nonscored.csv\")\nsub = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")\n\n# New data file available from 3rd November\ndrug = pd.read_csv('../input/lish-moa/train_drug.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Targets = train_targets_scored.columns[1:]\nScored = train_targets_scored.merge(drug, on='sig_id', how='left')\nScored","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def label_encoding(train: pd.DataFrame, test: pd.DataFrame, encode_cols):\n    n_train = len(train)\n    train = pd.concat([train, test], sort=False).reset_index(drop=True)\n    \n    for f in encode_cols:\n        try:\n            lbl = preprocessing.LabelEncoder()\n            train[f] = lbl.fit_transform(list(train[f].values))\n        except:\n            print(f)\n    test = train[n_train:].reset_index(drop=True)\n    train = train[:n_train]\n    \n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Manually self annotation with domain knowledge\nannot = pd.read_csv(\"../input/moa-annot-data/20201024_moa_sig_list.v2.csv\")\nannot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"annot_sig = []\nannot_sig = annot.sig_id.tolist()\nprint(annot_sig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target = pd.concat([train_targets_scored, train_targets_nonscored], axis=1)\ntrain_target.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For feature fngineering based on featrue importance with lgbm \n#importance_cols = pd.read_csv(\"../input/moa-annot-data/importance_cols_df.v67.csv\")\n#importance_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_odds = pd.read_csv(\"../input/moa-annot-data/20201121_train_targets_scored.matrix_odds_results.csv\")\nlog_odds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exclusive_cols = (\n    \"acetylcholine_receptor_agonist\", \n    \"acetylcholine_receptor_antagonist\", \n    \"adrenergic_receptor_agonist\",\n    \"adrenergic_receptor_antagonist\",\n    \"bacterial_cell_wall_synthesis_inhibitor\",\n    \"bacterial_dna_inhibitor\",\n    \"calcium_channel_blocker\",\n    \"cdk_inhibitor\",\n    \"dna_inhibitor\",\n    \"dopamine_receptor_agonist\",\n    \"dopamine_receptor_antagonist\",\n    \"egfr_inhibitor\",\n    \"estrogen_receptor_agonist\",\n    \"flt3_inhibitor\",\n    \"gaba_receptor_antagonist\",\n    \"glucocorticoid_receptor_agonist\",\n    \"glutamate_receptor_antagonist\",\n    \"histamine_receptor_antagonist\",\n    \"hmgcr_inhibitor\",\n    \"kit_inhibitor\",\n    \"mtor_inhibitor\",\n    \"nfkb_inhibitor\",\n    \"pdgfr_inhibitor\",\n    \"phosphodiesterase_inhibitor\",\n    \"pi3k_inhibitor\",\n    \"proteasome_inhibitor\",\n    \"serotonin_receptor_agonist\",\n    \"serotonin_receptor_antagonist\",\n    \"sodium_channel_inhibitor\",\n    \"tubulin_inhibitor\",\n    \"vegfr_inhibitor\"\n)\n       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"odds_gene2_df = pd.DataFrame()\n\nfor col in exclusive_cols:\n    odds_gene_df = log_odds[log_odds[\"Gene1\"]==col]\n    odds_gene2 = odds_gene_df[(odds_gene_df[\"p.value\"] <= 0.3) & (odds_gene_df[\"Log\"] < 0.0)][\"Gene2\"]\n\n    odds_gene2 = pd.DataFrame(odds_gene2)\n    odds_gene2 = odds_gene2.rename(columns={\"Gene2\": col}).reset_index(drop=True)\n    odds_gene2_df = pd.concat([odds_gene2_df, odds_gene2], axis=1)\n\n\nodds_gene2_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cope & paste from my v73 notebook\n\nunpredictable_cols = (\n 'acetylcholine_receptor_agonist',\n 'acetylcholine_receptor_antagonist',\n 'adenosine_receptor_antagonist',\n 'adrenergic_receptor_agonist',\n 'adrenergic_receptor_antagonist',\n 'anesthetic_-_local',\n 'atpase_inhibitor',\n 'aurora_kinase_inhibitor',\n 'bacterial_cell_wall_synthesis_inhibitor',\n 'bacterial_dna_gyrase_inhibitor',\n 'bacterial_dna_inhibitor',\n 'calcium_channel_blocker',\n 'cc_chemokine_receptor_antagonist',\n 'cdk_inhibitor',\n 'cyclooxygenase_inhibitor',\n 'cytochrome_p450_inhibitor',\n 'dna_inhibitor',\n 'dopamine_receptor_agonist',\n 'dopamine_receptor_antagonist',\n 'egfr_inhibitor',\n 'estrogen_receptor_agonist',\n 'flt3_inhibitor',\n 'gaba_receptor_agonist',\n 'gaba_receptor_antagonist',\n 'glucocorticoid_receptor_agonist',\n 'glutamate_receptor_antagonist',\n 'hdac_inhibitor',\n 'histamine_receptor_antagonist',\n 'hmgcr_inhibitor',\n 'kit_inhibitor',\n 'monoamine_oxidase_inhibitor',\n 'mtor_inhibitor',\n 'nfkb_inhibitor',\n 'pdgfr_inhibitor',\n 'phosphodiesterase_inhibitor',\n 'pi3k_inhibitor',\n 'potassium_channel_antagonist',\n 'ppar_receptor_agonist',\n 'progesterone_receptor_agonist',\n 'proteasome_inhibitor',\n 'protein_synthesis_inhibitor',\n 'raf_inhibitor',\n 'serotonin_receptor_agonist',\n 'serotonin_receptor_antagonist',\n 'sodium_channel_inhibitor',\n 'topoisomerase_inhibitor',\n 'tubulin_inhibitor',\n 'vegfr_inhibitor'\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Utils"},{"metadata":{"trusted":true},"cell_type":"code","source":"#===========================================================\n# training & inference model\n#===========================================================\n\ndef run_lgbm(target_col: str):\n    target = get_target(target_col, annot_sig)\n    target_rate = target.sum() / len(target)\n    \n    # estimate test target distribution\n    Adj_target_rate = (2*target_rate)/(target.sum()**0.15)\n    \n    trt = train[target==1].copy().reset_index(drop=True)\n    trt[\"target\"] = 1\n    trt = trt.drop(\"sig_id\", axis=1)\n    \n    # under sampling\n    othr =  Under_Sampling(train, target_col, target)\n    \n    logger.info(f\"{target_col}, len(trt): {len(trt)}, len(othr): {len(othr)}\")\n    logger.info(f\"target_rate: {target_rate:.7f} → Adj_target_rate: {Adj_target_rate:.7f}\")\n    \n    # Create train_data\n    X_train = pd.concat([trt, othr], axis=0, sort=False, ignore_index=True)   \n    y_train = X_train[\"target\"]\n    X_train = X_train.drop(\"target\", axis=1)\n    \n    # over sampling with SMOTE\n    if len(trt) < len(othr)*0.2:\n        sm = SMOTE(0.2, k_neighbors=3, random_state=SEED)\n        X_train, y_train = sm.fit_sample(X_train, y_train)\n        pos_neg_ratio = 0.8\n        \n    else:\n        pos_neg_ratio = 1-(len(trt)/len(othr))\n     \n    X_test = test.drop(\"sig_id\", axis=1)\n    \n    # pseudo_labeling\n    train_X, train_y, test_X, feature_importance_df_ = pseudo_labeling(X_train, y_train, X_test, target_rate, target_col, pos_neg_ratio)\n    \n    # fold_lgbm\n    y_preds_, train_y_, oof_train_, models = fold_lgbm(train_X, train_y,test_X, target_col)\n       \n    return sum(y_preds_) / len(y_preds_), train_y_, oof_train_, models, feature_importance_df_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge self annotated target func\n\ndef get_target(target_col, annot_sig):\n    if target_col in annot_sig:\n        t_cols = []\n        for t_col in list(annot[annot.sig_id == target_col].iloc[0]):\n            if t_col is not np.nan:\n                t_cols.append(t_col)\n                target = train_target[t_cols]\n                target = target.sum(axis=1)\n                #1 or more, replace it with 1.\n                target = target.where(target < 1, 1)\n    else:\n        target = train_targets_scored[target_col]\n    \n    return target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Under sampling func \n\ndef Under_Sampling(input_df, target_col, target):\n    \n    _df = input_df.copy()\n    \n    # under sampling with mutually exclusive columns\n    if target_col in exclusive_cols:\n        print(f\"mutually exclusive columns: {target_col}\")\n        target_exclusive = odds_gene2_df[target_col].dropna()\n        target_ex = train_targets_scored[list(target_exclusive)]\n        \n        # 1 or more, replace it with 1.\n        target_ex = target_ex.sum(axis=1)\n        target_ex = target_ex.where(target_ex < 1, 1)\n        \n        _df = _df[target_ex == 1].copy().reset_index(drop=True)\n        _df = _df.drop(\"sig_id\", axis=1)\n    \n    # under sampling with drug anotation(New data file)\n    else:\n        sig_id_lst = [list(Scored.sig_id[Scored.drug_id == id_].sample())[0] for id_ in Scored.drug_id.unique()]\n    \n        # Remove sig_id wih target \n        del_idx = train[target >= 1].sig_id.unique()\n        select_idx = [i for i in sig_id_lst if i not in del_idx]\n        \n        # Select negative target wiht multi_Stratification\n        _df = _df.set_index('sig_id')\n        _df = _df.loc[select_idx, :]\n        _df = _df.reset_index(drop=True)\n    \n    _df[\"target\"] = 0\n    print(f\"selected negative label: {len(_df)}\")\n    \n    return _df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lgbm with training & inference model\n\n\ndef fold_lgbm(train_X_, train_y_, test_X_, target_col):\n    \n    y_preds = []\n    oof_train = np.zeros((len(train_X_),))\n    score = 0\n    models = []\n    \n    _train_X, _train_y, _test_X = train_X_.copy(), train_y_.copy(), test_X_.copy()\n    \n    for fold_, (train_index, valid_index) in enumerate(cv.split(_train_X, _train_y)):\n        logger.info(f'len(train_index) : {len(train_index)}')\n        logger.info(f'len(valid_index) : {len(valid_index)}')\n        \n        X_tr, X_val = _train_X.loc[train_index, :], _train_X.loc[valid_index, :]\n        y_tr, y_val = _train_y[train_index], _train_y[valid_index]\n\n        lgb_train = lgb.Dataset(X_tr, y_tr, categorical_feature=categorical_cols)\n        lgb_eval = lgb.Dataset(X_val,y_val, reference=lgb_train,categorical_feature=categorical_cols)\n        \n        if target_col in unpredictable_cols:\n            \n            params = {\n                'objective': 'binary',\n                'metric': 'binary_logloss',\n                'learning_rate': 0.1,\n                'num_threads': 4,\n                'verbose': -1,\n                'max_depth': Max_depth,\n                'num_leaves': int((Max_depth**2)*0.7),\n                'feature_fraction':0.005, \n                'lambda_l1': 0.1,\n                'lambda_l2': 300,\n                'bagging_fraction': 0.7,\n                'bagging_freq': 1,\n            }\n            \n        else:\n             params = {\n                'objective': 'binary',\n                'metric': 'binary_logloss',\n                'learning_rate': 0.1,\n                'num_threads': 4,\n                'verbose': -1,\n                'max_depth': Max_depth,\n                'num_leaves': int((Max_depth**2)*0.7),\n                'feature_fraction':0.009, \n                'lambda_l1': 0.1,\n                'lambda_l2': 3,\n                'bagging_fraction': 0.8,\n                'bagging_freq': 1,\n            }\n            \n            \n            \n        \n        logger.info(f\"================================= fold {fold_+1}/{cv.get_n_splits()} {target_col}=================================\")\n        \n        model = lgb.train(params,\n                          lgb_train,\n                          valid_sets=[lgb_train, lgb_eval],\n                          verbose_eval=1000,\n                          num_boost_round=Num_boost_round,\n                          early_stopping_rounds=Early_stopping_rounds)\n        \n        oof_train[valid_index] = model.predict(X_val, num_iteration=model.best_iteration)\n\n        y_pred = model.predict(_test_X, num_iteration=model.best_iteration)\n        y_preds.append(y_pred)\n        \n        models.append(model)\n     \n    return y_preds, _train_y, oof_train, models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#===========================================================\n# pseudo_labeling func\n#===========================================================\n\ndef pseudo_labeling(X_train, y_train, X_test, target_rate, target_col, pos_neg_ratio, max_iter=3):\n    \n    #X, y, X_test = select_data(target_col, X_train, y_train, X_test)  \n    X, y, X_test = X_train.copy(), y_train.copy(), X_test.copy()\n    feature_importance_df = pd.DataFrame()\n    \n    for iter_ in range(1, max_iter+1):\n    \n        logger.info(f\"================= Pseudo labeling {iter_} / {max_iter} =================\")\n        \n        y_preds = np.zeros((X.shape[0], 2))\n        y_preds[:, 0] = y.copy()\n        y_prob = np.zeros((X_test.shape[0]))\n        X_conf, y_conf, _importance_df= pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n        _importance_df[\"Feature\"] = X.columns\n        \n        y_preds, y_prob, feature_importance_df = fold_lgbmclassifier(X, y, X_test, y_preds, y_prob, _importance_df, feature_importance_df, target_col)\n        \n        auc_score = roc_auc_score(y_preds[:, 0], y_preds[:, 1])\n        pr_score = average_precision_score(y_preds[:, 0], y_preds[:, 1])\n         \n        logger.info(f\"{iter_} / {max_iter}, AUC score:{auc_score:.3f}, PR-AUC:{pr_score:.3f}\") \n        y_preds = pd.DataFrame(y_preds, index=X.index, columns=[[\"Labels\", \"Preds\"]])\n        \n        if iter_ == 1:\n            quantile = pos_neg_ratio\n            Threshold = np.quantile(y_prob, q=0.99)\n        else:\n            quantile = 1.0 - y_label_rate\n        \n        y_Threshold = y_preds.iloc[:, 1].quantile(quantile)\n        logger.info(f\"y_Threshold: {y_Threshold:.7f}, Threshold: {Threshold:.7f}, pos_neg_ratio: {pos_neg_ratio:.7f}\")\n            \n        y_preds.iloc[:,1] = y_preds.iloc[:,1].where(y_preds.iloc[:,1] < y_Threshold, 1).copy()\n        y_preds.iloc[:,1] = y_preds.iloc[:,1].where(y_preds.iloc[:,1] >= y_Threshold, 0).copy()\n        y_preds = y_preds.sum(axis=1)\n                \n        corect_idx = y_preds[y_preds != 1].index.values\n        \n        X_corect, y_corect = X[X.index.isin(corect_idx)], y[y.index.isin(corect_idx)]\n        \n        logger.info(f\"Remove_noisy_data: {len(y)-len(y_corect)} → Positive_corect_labels: {sum(y_corect)}/{len(y_corect)}\")\n            \n        # Remove low confidence labels\n        y_prob = pd.DataFrame(y_prob, index=X_test.index, columns=[\"probability\"])\n        \n        lower = (0.1*iter_) + 0.6\n        upper = 2.0 - lower\n        \n        high_conf_0, high_conf_1 = min(Threshold*lower, 0.79), min(Threshold*upper, 0.97)\n        p_label, conf_idx = convert_label(y_prob, high_conf_0, high_conf_1, Threshold)\n        \n        p_label_rate = sum(p_label)/len(p_label)        \n        logger.info(f\"p_label_rate: {p_label_rate:.7f} Vs.target_rate: {target_rate:.5f}\")\n        logger.info(f\"Num_p_label: {sum(p_label)}, Expected: {(len(y_prob)*target_rate):.1f}, Threshold: {Threshold:.7f}, conf_0:{high_conf_0:.5f}, conf_1:{high_conf_1:.5f}\")\n        \n        # set the threshold based on train labels distribution (target_rate)\n        if p_label_rate > target_rate:\n            p_label, conf_idx, high_conf_0, high_conf_1, Threshold = Adj_threshold(p_label, conf_idx, high_conf_0, high_conf_1, Threshold, target_rate, y_prob, lower, upper)\n        \n        # select data with confidence            \n        X_conf = X_test[X_test.index.isin(conf_idx)].copy()\n        X, y = pd.concat([X_corect, X_conf], axis=0, ignore_index=True), pd.concat([y_corect, p_label], axis=0, ignore_index=True)\n        \n        logger.info(f\"threshold: {Threshold:.7f}, positive_p_label: {sum(p_label)}/{len(p_label)}, p_label_rate: {sum(p_label)/len(p_label):.7f}\")\n        \n        # updated train data\n        X = X.drop_duplicates(keep=\"last\").reset_index(drop=True)\n        y = y[X.index.values].reset_index(drop=True)\n        \n        y_label_rate = sum(y)/len(y)\n        logger.info(f\"positive_y_label: {sum(y)}/{len(y)}, y_label_rate: {y_label_rate:.7f}\")\n        \n    show_feature_importance(feature_importance_df, target_col, num=10)\n        \n    return X, y, X_test, feature_importance_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lgbm with pseudo_labeling\n\ndef fold_lgbmclassifier(X_, y_, X_test_, _y_preds, _y_prob, _importance_df, feature_importance_df_, target_col):\n    \n    _X, _y, _X_test = X_.copy(), y_.copy(), X_test_.copy()\n    \n    for fold_, (train_idx, valid_idx) in enumerate(cv.split(_X, _y)):\n        \n        X_tr, X_val = _X.loc[train_idx, :], _X.loc[valid_idx, :]\n        y_tr, y_val = _y[train_idx], _y[valid_idx]\n        \n        if target_col in unpredictable_cols:\n            classifier_params = {\n                'max_depth': Max_depth,\n                'num_leaves': int((Max_depth**2)*0.7),\n                'n_estimators': Num_boost_round,\n                'learning_rate': 0.1,\n                'objective': \"binary\",\n                'colsample_bytree': 0.005,\n                'subsample': 0.7,\n                'subsample_freq': 1,\n                'reg_alpha': 0.1,\n                'reg_lambda': 200,\n                'random_state': SEED,\n                'n_jobs': 4\n            }\n            \n        else:\n            classifier_params = {\n                'max_depth': Max_depth,\n                'num_leaves': int((Max_depth**2)*0.7),\n                'n_estimators': Num_boost_round,\n                'learning_rate': 0.05,\n                'objective': \"binary\",\n                'colsample_bytree': 0.009,\n                'subsample': 0.8,\n                'subsample_freq': 1,\n                'reg_alpha': 0.1,\n                'reg_lambda': 0.1,\n                'random_state': SEED,\n                'n_jobs': 4\n            }\n            \n            \n        clf = LGBMClassifier(**classifier_params)\n            \n        clf.fit(X_tr, y_tr,\n                eval_set=[(X_tr, y_tr), (X_val, y_val)],\n                eval_metric='logloss',\n                verbose=1000,\n                early_stopping_rounds=Early_stopping_rounds)\n            \n        _y_preds[valid_idx, 1] = clf.predict_proba(X_val, num_iteration=clf.best_iteration_)[:, 1]\n        _y_prob += clf.predict_proba(_X_test, num_iteration=clf.best_iteration_)[:, 1] / N_FOLD\n            \n        # feature importance with target col\n        _importance_df[\"importance\"] = clf.feature_importances_\n        feature_importance_df_ = pd.concat([feature_importance_df_, _importance_df], axis=0)\n        \n    return _y_preds, _y_prob, feature_importance_df_\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# select important features with pseudo_labeling\n\ndef select_data(target_col, X_train_, y_train_, X_test_):\n    \n    selected_cols = importance_cols[target_col]\n    _X, _y, _X_test = X_train_.copy(), y_train_.copy(), X_test_.copy()\n    _X, _X_test = _X[selected_cols], _X_test[selected_cols]\n    \n    X_, X_test_ = create_features(_X, _X_test)\n    \n    logger.info(f'N_features:{len(X_.columns)}')\n\n    return X_, _y, X_test_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create features with pseudo_labeling\n\ndef create_features(df_trt, df_tst):\n    \n    from sklearn.decomposition import PCA\n    \n    df_trt['WHERE'], df_tst['WHERE'] = 'trt', 'tst'\n    _df = df_trt.append(df_tst)\n    _df = _df.reset_index(drop=True)\n    _Splitdata = _df[\"WHERE\"]\n    _df = _df.drop('WHERE', axis=1)\n    \n    pca_transformer = PCA(n_components=0.9, whiten=True, random_state=SEED)\n    _pca = pca_transformer.fit_transform(_df)\n    _pca_df = pd.DataFrame(_pca)\n    pca_cols = [f\"pca_{i+1}\" for i in range(_pca_df.shape[1])]\n    _pca_df.columns = pca_cols\n    \n    _df = pd.concat([_df, _pca_df], axis=1)\n    \n    _df['WHERE'] = _Splitdata\n    trt_ = _df[_df['WHERE']==\"trt\"].drop('WHERE', axis=1).reset_index(drop=True)\n    tst_ = _df[_df['WHERE']==\"tst\"].drop('WHERE', axis=1).reset_index(drop=True)\n    \n    return trt_, tst_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert labels with pseudo_labeling\n\ndef convert_label(input_df, conf_0, conf_1, threshold=0.5):\n    \n    _df = input_df.copy()\n    Probability = _df.iloc[:, 0]\n    \n    # Remove low confidence labels\n    conf_index = _df[(Probability <= conf_0) & (conf_1 <= Probability)].index.values\n    \n    Probability = Probability.where(Probability < threshold, 1).copy()\n    p_label = Probability.where(Probability >= threshold, 0).copy()\n    \n    return p_label, conf_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adj threshold with pseudo_labeling\n\ndef Adj_threshold(p_label, conf_idx, high_conf_0, high_conf_1, Threshold_, target_rate, y_prob, lower_, upper_):\n    \n    check = len(y_prob)*target_rate\n        \n    for i in range(10):\n        if (sum(p_label) <= check*(3.5-len(str(int(check))))) or (Threshold_ >= 0.96): break\n            \n        Threshold_ += 0.03\n        high_conf_0, high_conf_1 = min(Threshold_*lower_, 0.79), min(Threshold_*upper_, 0.97)\n        p_label, conf_idx = convert_label(y_prob, high_conf_0, high_conf_1, Threshold_)\n        logger.info(f\"Num_p_label: {sum(p_label)}, Expected: {check:.1f}, Adj_threshold_{i+1}: {Threshold_:.7f}\")\n            \n    return p_label, conf_idx, high_conf_0, high_conf_1, Threshold_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check importance features with pseudo_labeling\n\ndef show_feature_importance(feature_importance_df, title=\"all\", num=100):\n    cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n            .groupby(\"Feature\")\n            .mean()\n            .sort_values(by=\"importance\", ascending=False)[:num].index)\n    \n    best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n    \n    hight = int(num//3.3)\n    plt.figure(figsize=(8, hight))\n    sns.barplot(x=\"importance\", \n                y=\"Feature\", \n                data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title(f'{title}_Features importance (averaged)')\n    plt.tight_layout()\n    plt.savefig(f\"./{title}_feature_importance_{Version}.png\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing\n\nWe have to convert some categorical features into numbers in train and test. We can identify categorical features by `pd.DataFrame.select_dtypes`."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.select_dtypes(include=['object']).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = label_encoding(train, test, ['cp_type', 'cp_time', 'cp_dose'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['WHERE'] = 'train'\ntest['WHERE'] = 'test'\n\ndata = train.append(test)\ndata = data.reset_index(drop=True)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select control data\nctl = train[(train.cp_type==0)].copy()\nctl = ctl.reset_index(drop=True)\nctl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clipping for control data\n\ndef outlier_clip(df):\n    df = df.copy()\n    clipping = df.columns[4:6]\n    for col in clipping:\n        lower, upper= np.percentile(df[col], [10, 90])\n        df[col] = np.clip(df[col], lower, upper)\n    \n    return df\n\nctl_df = pd.DataFrame(columns=train.columns)\nfor i in ctl.cp_time.unique():\n    for j in ctl.cp_dose.unique():\n        print(len(ctl[(ctl.cp_time==i) & (ctl.cp_dose==j)]))\n        tmp_ctl = ctl[(ctl.cp_time==i) & (ctl.cp_dose==j)]\n        tmp_ctl = outlier_clip(tmp_ctl)\n        ctl_df = pd.concat([ctl_df, tmp_ctl], axis=0).reset_index(drop=True)\nctl_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_list = list(data.columns)[:-1]\ndata_df = pd.DataFrame(columns=col_list)\nSplitdata = []\nd = 1e-6\n\nfor i in tqdm(data.cp_time.unique()):\n    for j in data.cp_dose.unique():\n        select = data[(data.cp_time==i) & (data.cp_dose==j)]\n        print(len(select))\n        \n        for k in list(select['WHERE']): Splitdata.append(k)\n        \n        select = select.drop(columns='WHERE')\n        med = ctl[(ctl.cp_time==i) & (ctl.cp_dose==j)].iloc[:, 4:].median()\n        \n        f_div = lambda x: ((10*x+d)/(med+d))**3\n        select_div = select.iloc[:,4:].apply(f_div, axis=1).add_prefix('d_')\n        tmp_data = pd.concat([select, select_div], axis=1, sort=False)\n        \n        \n        f_diff = lambda x: ((x-med)*10)**2\n        select_diff = select.iloc[:,4:].apply(f_diff, axis=1).add_prefix('df_')\n        tmp_data = pd.concat([tmp_data, select_diff], axis=1, sort=False)\n        \n        data_df = pd.concat([data_df, tmp_data], axis=0)\n        \ndata_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g_list = [col for col in data.columns[4:] if col.startswith(\"g-\")]\nc_list = [col for col in data.columns[4:] if col.startswith(\"c-\")]\n\n# clipping\nclipping = data_df.columns[4+len(g_list):]\nfor col in tqdm(clipping):\n    lower, upper = np.percentile(data_df[col], [1, 99])\n    data_df[col] = np.clip(data_df[col], lower, upper)\ndata_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df = data_df.replace([np.inf, -np.inf], np.nan)\ndata_df = data_df.dropna(how='any', axis=1)\ndata = data_df.copy()\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_g_list = [col for col in data.columns[4:] if col.startswith(\"d_g-\")]\nd_c_list = [col for col in data.columns[4:] if col.startswith(\"d_c-\")]\ndf_g_list = [col for col in data.columns[4:] if col.startswith(\"df_g-\")]\ndf_c_list = [col for col in data.columns[4:] if col.startswith(\"df_c-\")]\n\ng_d_g_list = g_list + d_g_list \nc_d_c_list = c_list + d_c_list\n\ng_df_g_list = g_list + df_g_list\nc_df_c_list = c_list + df_c_list\n\nd_g_df_g_list = d_g_list + df_g_list\nd_c_df_c_list = d_c_list + df_c_list\n\ng_all_list = g_list + d_g_list + df_g_list\nc_all_list = c_list + d_c_list + df_c_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, QuantileTransformer\n    \n# Z-score\n# scaler = StandardScaler(with_mean=True, with_std=True)\n\n# RankGauss\nscaler = QuantileTransformer(output_distribution='normal', random_state=SEED)\n\n# Without Z-scored gene expression data\nfor col in tqdm(data.columns[4+len(g_list):]):\n    size = len(data[col].values)\n    \n    raw = data[col].values.reshape(size, 1)\n    scaler.fit(raw)\n\n    data[col] = scaler.transform(raw).reshape(1, size)[0]\n    \ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#std_df = data.iloc[:, 4:].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_list = (g_list, \n                c_list, \n                d_g_list, \n                d_c_list, \n                df_g_list,\n                df_c_list, \n                g_d_g_list, \n                c_d_c_list, \n                g_df_g_list, \n                c_df_c_list, \n                d_g_df_g_list, \n                d_c_df_c_list,\n                g_all_list, \n                c_all_list)\n\n\nkind_list = ('g', \n             'c', \n             'd_g', \n             'd_c', \n             'df_g', \n             'df_c',  \n             'g_d_g', \n             'c_d_c', \n             'g_df_g', \n             'c_df_c', \n             'd_g_df_g', \n             'd_c_df_c',\n             'g_all', \n             'c_all')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"std_df = data.iloc[:, 4:].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_bin = 7\n\nfor col_ in tqdm(std_df.columns):\n    std_df[f\"cut_{col_}\"] = pd.cut(std_df[col_], N_bin, labels=False)\n\n# Count bin_cnt types\nfor i in tqdm(range(N_bin-1, -1, -1)):\n    std_df[f\"bin_cnt_{i}\"] = std_df.apply(lambda x: (x == i).sum(), axis=1)\nstd_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_clusters = 7\n\ndef create_cluster(data, features, n_clusters):\n    \n    from sklearn.cluster import KMeans\n    \n    _data = data[features].copy()\n    kmeans = KMeans(n_clusters = n_clusters, random_state = SEED).fit(_data)\n    cluster_label = kmeans.labels_[:_data.shape[0]]\n \n    return cluster_label\n\n\ndef detect_cluster(data, feature_list, kind_list, n_clusters):\n    \n    _data = data.copy()\n    \n    for idx, feature in enumerate(tqdm(feature_list)):\n        _data[f'clusters_{kind_list[idx]}'] = create_cluster(data, feature, n_clusters=n_clusters)\n    \n    _data = _data.iloc[:, -len(feature_list):].copy()\n    \n    return _data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clusters = detect_cluster(data, feature_list, kind_list, n_clusters)\nclusters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count cluster types\nfor i in tqdm(range(n_clusters-1, -1, -1)):\n    clusters[f\"cnt_{i}\"] = clusters.apply(lambda x: (x == i).sum(), axis=1)\nclusters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fe_stats(df, features, kind):\n    \n    df_ = df.copy()\n    d = 1e-6\n    MAX = df_[features].max(axis = 1) \n    MIN = df_[features].min(axis = 1)\n    Kurt = df_[features].kurtosis(axis = 1)\n    Skew = df_[features].skew(axis = 1)\n    SUM = df_[features].sum(axis = 1)\n    MAD = df_[features].mad(axis = 1)\n    STD = df_[features].std(axis = 1)\n    \n    df_[f'{kind}_max'] = MAX\n    df_[f'{kind}_min'] = MIN\n    df_[f'{kind}_max_min_p'] = MAX*MIN\n    df_[f'{kind}_max_min_d'] = (MAX+d)/(MIN+d)\n    \n    df_[f'{kind}_kurt'] = Kurt\n    df_[f'{kind}_max_kurt_p'] = MAX*Kurt\n    df_[f'{kind}_min_kurt_p'] = MIN*Kurt\n    df_[f'{kind}_max_kurt_d'] = (MAX+d)/(Kurt+d)\n    df_[f'{kind}_min_kurt_d'] = (MIN+d)/(Kurt+d)\n    \n    df_[f'{kind}_skew'] = Skew\n    df_[f'{kind}_max_skew_p'] = MAX*Skew\n    df_[f'{kind}_min_skew_p'] = MIN*Skew\n    df_[f'{kind}_max_skew_d'] = (MAX+d)/(Skew+d)\n    df_[f'{kind}_min_skew_d'] = (MIN+d)/(Skew+d)\n    \n    df_[f'{kind}_kurt_skew_p'] = Kurt*Skew\n    df_[f'{kind}_kurt_skew_d'] = (Kurt+d)/(Skew+d)\n    \n    df_[f'{kind}_sum'] = SUM\n    df_[f'{kind}_max_sum_p'] = MAX*SUM\n    df_[f'{kind}_min_sum_p'] = MIN*SUM\n    df_[f'{kind}_max_sum_d'] = (MAX+d)/(SUM+d)\n    df_[f'{kind}_min_sum_d'] = (MIN+d)/(SUM+d)\n    \n    df_[f'{kind}_mad'] = MAD\n    df_[f'{kind}_max_mad_p'] = MAX*MAD\n    df_[f'{kind}_min_mad_p'] = MIN*MAD\n    df_[f'{kind}_max_mad_d'] = (MAX+d)/(MAD+d)\n    df_[f'{kind}_min_mad_d'] = (MIN+d)/(MAD+d)\n    \n    df_[f'{kind}_std'] = STD\n    df_[f'{kind}_max_std_p'] = MAX*STD\n    df_[f'{kind}_min_std_p'] = MIN*STD\n    df_[f'{kind}_max_std_d'] = (MAX+d)/(STD+d)\n    df_[f'{kind}_min_std_d'] = (MIN+d)/(STD+d)\n    \n    df_[f'{kind}_mean'] = df_[features].mean(axis = 1)\n    df_[f'{kind}_median'] = df_[features].median(axis = 1)\n\n    return df_\n\ndef detect_stats(data, feature_list, kind_list):\n    \n    for idx, feature in enumerate(tqdm(feature_list)):\n        data = fe_stats(data, feature, kind=kind_list[idx])\n\n    stats = data.iloc[:, -33*len(feature_list):].copy()\n    \n    return stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats = detect_stats(data, feature_list, kind_list)\nstats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add data with sig_id, cp_type, cp_time, and cp_dose\ndata = pd.concat([data.iloc[:, :4], clusters], axis=1)\ndata = pd.concat([data, stats], axis=1)\ndata = pd.concat([data, std_df], axis=1)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clipping\n\nclipping = data.columns[4:]\n\nfor col in tqdm(clipping):\n    lower, upper = np.percentile(data[col], [1, 99])\n    data[col] = np.clip(data[col], lower, upper)\n    \ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['WHERE'] = Splitdata\ntrain = data[data['WHERE']==\"train\"].drop('WHERE', axis=1).reset_index(drop=True)\ntest = data[data['WHERE']==\"test\"].drop('WHERE', axis=1).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = StratifiedKFold(n_splits=N_FOLD, shuffle=True, random_state=SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def select_importance_cols(feature_importance_df, num=500):\n    best_cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n            .groupby(\"Feature\")\n            .mean()\n            .sort_values(by=\"importance\", ascending=False)[:num].index)\n    return best_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_featureimprotance(models, feature_importance_df):\n    for model in models:\n        _importance_df = pd.DataFrame()\n        _importance_df[\"Feature\"] = train.columns[1:]\n        _importance_df[\"importance\"] = model.feature_importance(importance_type='gain')\n        feature_importance_df = pd.concat([feature_importance_df, _importance_df], axis=0)\n        \n        return feature_importance_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols = []\nimportance_cols_df = pd.DataFrame()\n\ndef RUN():\n    \n    scores = []\n    unpredictable = []\n    \n    for target_col in tqdm(train_targets_scored.columns[1:]):\n    #for target_col in ('acetylcholine_receptor_agonist','acetylcholine_receptor_antagonist',):\n        \n        _score = 0.0\n        feature_importance_df = pd.DataFrame()\n        models = []\n        \n        _preds, _train_y, _oof_train, models, _feature_importance_df = run_lgbm(target_col)\n        sub[target_col] = _preds\n        \n        _score = log_loss(_train_y, _oof_train)\n        scores.append(_score)\n        \n        feature_importance_df = create_featureimprotance(models, feature_importance_df)\n        importance_cols_df[target_col] = select_importance_cols(_feature_importance_df)\n        \n        logger.info(f\"=========================================================================================\")\n        logger.info(f\"{target_col} logloss: {_score}\")\n        \n        if _score > 0.03:\n            unpredictable.append(target_col)\n            logger.info(f\"{target_col} is unpredictable(><)!\")\n        \n        \n        logger.info(f\"=========================================================================================\")\n        logger.info(f\"=========================================================================================\")\n        \n    logger.info(f\"=========================================================================================\")\n    \n    sub.to_csv('submission.csv', index=False)\n    logger.info(f\"CV:{np.mean(scores)}\")\n    \n    \n    feature_importance_df.to_csv(f'feature_importance_df.{Version}.csv', index=False)\n    importance_cols_df.to_csv(f'importance_cols_df.{Version}.csv', index=False)\n        \n    show_feature_importance(feature_importance_df)\n    \n    return unpredictable\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unpredictable = RUN()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unpredictable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}